{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54d78433-5c11-444d-b63a-cac9d2f8d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3745cc48-c1c2-417d-a488-8717853cfc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df = pd.read_csv('data.csv')\n",
    "df.rename(columns=lambda x: x.strip(), inplace=True) # Remove leading/trailing whitespaces from column names\n",
    "df.drop(columns=[\"Net Income Flag\"], inplace=True)   # Drop the 'Net Income Flag' column as it's not needed\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop(columns=[\"Bankrupt?\"])   # Features\n",
    "y = df[\"Bankrupt?\"]                   # Target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fb97fd-39e2-4974-b003-82bc3ffa1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10-fold cross-validation setup\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2473e1d5-37ce-47e2-8cbf-a5aebf8198d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store performance metrics for Artificial Neural Network (ANN)\n",
    "ann_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': []}\n",
    "\n",
    "# Dictionary to store performance metrics for Naive Bayes (NB)\n",
    "nb_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': [], 'auc': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba07bae-2061-446d-b269-10ad74965d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Artificial Neural Network (ANN) model\n",
    "ann = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "# Parameters:\n",
    "# - hidden_layer_sizes: Tuple, length = n_layers - 2, default=(100,)\n",
    "#   The ith element represents the number of neurons in the ith hidden layer.\n",
    "# - max_iter: int, default=200\n",
    "#   Maximum number of iterations. The solver iterates until convergence or this number of iterations.\n",
    "# - random_state: int, RandomState instance, default=None\n",
    "#   Determines random number generation for weights and bias initialization, training data shuffling, etc.\n",
    "\n",
    "# Define the Naive Bayes (NB) model\n",
    "nb = GaussianNB()\n",
    "# Parameters:\n",
    "# GaussianNB does not have any specific parameters to define.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aee99cc-5f66-44f2-a790-a5f758270b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karde/.local/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models using 10-fold cross-validation\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train and evaluate the Artificial Neural Network (ANN) model\n",
    "    ann.fit(X_train, y_train)                # Train the ANN model\n",
    "    y_pred_ann = ann.predict(X_test)         # Predict using the ANN model\n",
    "    y_proba_ann = ann.predict_proba(X_test)[:, 1]  # Predict probabilities using the ANN model\n",
    "    \n",
    "    # Store performance metrics for the ANN model\n",
    "    ann_metrics['accuracy'].append(accuracy_score(y_test, y_pred_ann))\n",
    "    ann_metrics['precision'].append(precision_score(y_test, y_pred_ann))\n",
    "    ann_metrics['recall'].append(recall_score(y_test, y_pred_ann))\n",
    "    ann_metrics['f1'].append(f1_score(y_test, y_pred_ann))\n",
    "    ann_metrics['auc'].append(roc_auc_score(y_test, y_proba_ann))\n",
    "    \n",
    "    # Train and evaluate the Naive Bayes (NB) model\n",
    "    nb.fit(X_train, y_train)                 # Train the NB model\n",
    "    y_pred_nb = nb.predict(X_test)           # Predict using the NB model\n",
    "    y_proba_nb = nb.predict_proba(X_test)[:, 1]   # Predict probabilities using the NB model\n",
    "    \n",
    "    # Store performance metrics for the NB model\n",
    "    nb_metrics['accuracy'].append(accuracy_score(y_test, y_pred_nb))\n",
    "    nb_metrics['precision'].append(precision_score(y_test, y_pred_nb))\n",
    "    nb_metrics['recall'].append(recall_score(y_test, y_pred_nb))\n",
    "    nb_metrics['f1'].append(f1_score(y_test, y_pred_nb))\n",
    "    nb_metrics['auc'].append(roc_auc_score(y_test, y_proba_nb))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8780505-45b9-4958-bf21-673b454157c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform paired t-test between two sets of metrics\n",
    "def perform_ttest(metric1, metric2, metric_name):\n",
    " \n",
    "    # Perform paired t-test\n",
    "    t_stat, p_value = ttest_rel(metric1, metric2)\n",
    "    \n",
    "    # Print t-statistic and p-value\n",
    "    print(f\"{metric_name} - t-statistic: {t_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "    \n",
    "    # Interpret the test results based on the p-value\n",
    "    if p_value < 0.05:\n",
    "        print(f\"Reject the null hypothesis: There is a significant difference in {metric_name} between the models.\")\n",
    "    else:\n",
    "        print(f\"Fail to reject the null hypothesis: No significant difference in {metric_name} between the models.\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025e3452-1ebe-4058-89fd-2f2139ea81ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - t-statistic: 23.2105, p-value: 0.0000\n",
      "Reject the null hypothesis: There is a significant difference in Accuracy between the models.\n",
      "\n",
      "Precision - t-statistic: 2.1127, p-value: 0.0638\n",
      "Fail to reject the null hypothesis: No significant difference in Precision between the models.\n",
      "\n",
      "Recall - t-statistic: -19.8578, p-value: 0.0000\n",
      "Reject the null hypothesis: There is a significant difference in Recall between the models.\n",
      "\n",
      "F1 - t-statistic: 1.1751, p-value: 0.2701\n",
      "Fail to reject the null hypothesis: No significant difference in F1 between the models.\n",
      "\n",
      "Auc - t-statistic: -3.4304, p-value: 0.0075\n",
      "Reject the null hypothesis: There is a significant difference in Auc between the models.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform t-test for each performance metric\n",
    "for metric in ann_metrics.keys():\n",
    "    # Call the perform_ttest function for each metric\n",
    "    perform_ttest(ann_metrics[metric], nb_metrics[metric], metric.capitalize())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5917827e-f933-4021-9cf2-8c803fa22838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN Metrics (10-fold CV):\n",
      "Accuracy: Mean = 0.9402, Std = 0.0258\n",
      "Precision: Mean = 0.1232, Std = 0.1283\n",
      "Recall: Mean = 0.1000, Std = 0.0808\n",
      "F1: Mean = 0.0915, Std = 0.0715\n",
      "Auc: Mean = 0.5302, Std = 0.0329\n",
      "\n",
      "Naive Bayes Metrics (10-fold CV):\n",
      "Accuracy: Mean = 0.1016, Std = 0.1097\n",
      "Precision: Mean = 0.0324, Std = 0.0021\n",
      "Recall: Mean = 0.9273, Std = 0.1098\n",
      "F1: Mean = 0.0626, Std = 0.0038\n",
      "Auc: Mean = 0.6536, Std = 0.0958\n"
     ]
    }
   ],
   "source": [
    "# Print performance metrics \n",
    "print(\"ANN Metrics (10-fold CV):\")\n",
    "for metric, values in ann_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: Mean = {np.mean(values):.4f}, Std = {np.std(values):.4f}\")\n",
    "\n",
    "print(\"\\nNaive Bayes Metrics (10-fold CV):\")\n",
    "for metric, values in nb_metrics.items():\n",
    "    print(f\"{metric.capitalize()}: Mean = {np.mean(values):.4f}, Std = {np.std(values):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294d0d7c-f6a7-4dd7-9f74-69501c58ed4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
